{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_covid19-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCTBtJ78AphPdb57pdtaha",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhmuller/mlp-covid19/blob/main/mlp_covid19_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlYvPvDW-8F4"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\r\n",
        "import unicodedata\r\n",
        "import string\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import re\r\n",
        "import random\r\n",
        "from tqdm import tqdm\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "def whoami(): \r\n",
        "    return sys._getframe(1).f_code.co_name\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWzTBU7FR1pR",
        "outputId": "32d97273-4ac8-40c4-fd1d-8157e25f45a8"
      },
      "source": [
        "# need to intall this every time on colab, not sure why but I do it\r\n",
        "import importlib\r\n",
        "import warnings\r\n",
        "import pdb\r\n",
        "import datetime\r\n",
        "now = datetime.datetime.now\r\n",
        "def warning_on_one_line(message, category, filename, lineno, file=None, line=None):\r\n",
        "    return 'line:%s  cat:<%s>  msg:%s\\n'% (lineno, category.__name__, message)  \r\n",
        "\r\n",
        "warnings.formatwarning = warning_on_one_line\r\n",
        "\r\n",
        "def global_imports(imports=None, verbosity=0):\r\n",
        "  fails = []\r\n",
        "  if not imports:\r\n",
        "    return\r\n",
        "  if not isinstance(imports, list):\r\n",
        "    msg = \"imports shoule be a list with elements like\\m\"\r\n",
        "    msg += \"'foo' or 'foo as bar'\"\r\n",
        "    warnings.warn(msg)\r\n",
        "    return\r\n",
        "  for line in imports:\r\n",
        "    parts = line.split()\r\n",
        "    if len(parts) not in [1,3] or \\\r\n",
        "          (len(parts) == 3 and parts[1] != 'as'):\r\n",
        "      msg = \"<{0}> not a valid import line\\n\"\r\n",
        "      msg += \"use 'import foo' or 'import foo as bar'\"\r\n",
        "      warnings.warn(msg)\r\n",
        "      continue\r\n",
        "    module_name = parts[0]\r\n",
        "    asname = parts[0]\r\n",
        "    if len(parts) == 3:\r\n",
        "      asname = parts[2]\r\n",
        "    try:\r\n",
        "      module = importlib.import_module(module_name)\r\n",
        "      globals()[asname] = module\r\n",
        "    except Exception as e:\r\n",
        "      print(e)\r\n",
        "      print(\"{0} not installed\\Trying to install it\".format(module_name))\r\n",
        "      try:\r\n",
        "        !pip install $module_name\r\n",
        "        module = importlib.import_module(module_name)  \r\n",
        "        globals()[asname] = module        \r\n",
        "      except Exception as e2:\r\n",
        "        print(e2)\r\n",
        "        fails.append(module_name)\r\n",
        "  if fails:\r\n",
        "    msg = \"Not able to import or install\\n{0}\".format(fails)\r\n",
        "  else:\r\n",
        "    msg = \"Success. imported {0}\".format(imports)\r\n",
        "  if verbosity > 0:\r\n",
        "    print(msg)\r\n",
        "  return fails\r\n",
        "    \r\n",
        "def is_defined(varnames=None, verbosity=0):\r\n",
        "  if isinstance(varnames, str):\r\n",
        "    varnames = [varnames]\r\n",
        "  for v in varnames:\r\n",
        "    try:\r\n",
        "      eval(v)\r\n",
        "      if verbosity > 0:\r\n",
        "        print(\"'{0}'' is defined\")\r\n",
        "    except Exception as e:\r\n",
        "      warnings.warn(\"trying to eval '{0}'\".format(v))\r\n",
        "      print(e)\r\n",
        "\r\n",
        "imports = [ 'fsspec',\r\n",
        "           'nltk',\r\n",
        "            'pandas as pd',\r\n",
        "            'numpy as np']\r\n",
        "varnames = ['fsspec', 'pd']\r\n",
        "global_imports(imports, verbosity=1)\r\n",
        "# check if the imports worked\r\n",
        "is_defined([x.split()[-1] for x in imports])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success. imported ['fsspec', 'nltk', 'pandas as pd', 'numpy as np']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNuL6gyuAfyX"
      },
      "source": [
        "import time\r\n",
        "import math\r\n",
        "\r\n",
        "\r\n",
        "def asMinutes(s):\r\n",
        "  m = math.floor(s / 60)\r\n",
        "  s -= m * 60\r\n",
        "  return '%dm %ds' % (m, s)\r\n",
        "\r\n",
        "\r\n",
        "def timeSince(since, percent):\r\n",
        "  now = time.time()\r\n",
        "  s = now - since\r\n",
        "  es = s / (percent)\r\n",
        "  rs = es - s\r\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqBScAAq33gj"
      },
      "source": [
        "# I am *guessing* this is max_len_text from part 1\r\n",
        "max_length_text = 600\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftGu34q6frDI",
        "outputId": "075250c6-dae8-4b6d-cd41-b98da6dda431"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\r\n",
        "  print('Running on CoLab')\r\n",
        "  # to mount google drive for the input files\r\n",
        "  from google.colab import drive\r\n",
        "  drive.mount('/content/gdrive', force_remount=False)  \r\n",
        "  dpath = \"/content/gdrive/My Drive/mlp_covid19/data/part1_output\"  \r\n",
        "else:\r\n",
        "  print('Not running on CoLab')\r\n",
        "  dpath = \"./mlp_covid19/data/part1_output\"\r\n",
        "if not os.path.isdir(dpath):\r\n",
        "  msg = \"{0} is not a path\".format(dpath)\r\n",
        "  warnings.warn(msg)\r\n",
        "else:\r\n",
        "  files = os.listdir(dpath)\r\n",
        "  msg = \"{0} has {1} files\".format(dpath, len(files))\r\n",
        "  n2print = 4\r\n",
        "  suffix = \"...\" if len(files) > n2print else \"\"\r\n",
        "  fsizes =[os.path.getsize(os.path.join(dpath, fname)) for fname in files ]\r\n",
        "  for i, f in enumerate(files):\r\n",
        "    msg += \"\\n\\t'{0}' size: {1} MB  {2} GB\".format(f, np.round(fsizes[i]/10**6,2), \r\n",
        "                                             np.round(fsizes[i]/10**9, 3))\r\n",
        "  print(msg)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on CoLab\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/mlp_covid19/data/part1_output has 4 files\n",
            "\t'pairs_df_part1.csv' size: 123.59 MB  0.124 GB\n",
            "\t'input_lang_part1.parquet' size: 141.22 MB  0.141 GB\n",
            "\t'output_lang_part1.parquet' size: 6.41 MB  0.006 GB\n",
            "\t'pairs_part1.parquet' size: 124.92 MB  0.125 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3_JOii7j-8r"
      },
      "source": [
        "SOS_token = 0\r\n",
        "EOS_token = 1\r\n",
        "SOS_token = 0\r\n",
        "EOS_token = 1\r\n",
        "\r\n",
        "class Lang:\r\n",
        "    def __init__(self, name):\r\n",
        "        self.name = name\r\n",
        "        self.word2index = {}\r\n",
        "        self.word2count = {}\r\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n",
        "        self.n_words = 2  # Count SOS and EOS\r\n",
        "\r\n",
        "    def addSentence(self, sentence):\r\n",
        "        for word in sentence.split(' '):\r\n",
        "            self.addWord(word)\r\n",
        "\r\n",
        "    def addWord(self, word):\r\n",
        "        if word not in self.word2index:\r\n",
        "            self.word2index[word] = self.n_words\r\n",
        "            self.word2count[word] = 1\r\n",
        "            self.index2word[self.n_words] = word\r\n",
        "            self.n_words += 1\r\n",
        "        else:\r\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf9zVdFWn28a",
        "outputId": "25dc937c-b862-4d3a-cdee-bf8a5ed4dade"
      },
      "source": [
        "def load_path_objects(dpath, \r\n",
        "                      force_reload=True,\r\n",
        "                      extensions=(\"parquet\", \"csv\"),\r\n",
        "                      verbosity=0):\r\n",
        "  if verbosity > 0:\r\n",
        "    print(\"\\n{0} force_reload= {1}, extensions={2}\".format(whoami(),\r\n",
        "                                                        force_reload,\r\n",
        "                                                         extensions))  \r\n",
        "  import pickle\r\n",
        "  if not extensions:\r\n",
        "    warnings.warn(\"No extensions\")\r\n",
        "    return None\r\n",
        "  res = {}  \r\n",
        "  known_exts = {\"parquet\", \"csv\"}\r\n",
        "  all_files = [fname for fname in os.listdir(dpath)]\r\n",
        "  all_exts = set([file.split(\".\")[-1] for file in all_files])\r\n",
        "  unknown_exts = all_exts.difference(known_exts)\r\n",
        "  if len(unknown_exts) > 0:\r\n",
        "    if verbosity > 0:\r\n",
        "      known_str = \",\".join(known_extensions)\r\n",
        "      msg = \"Can only handle these extensions: [{0}]\".format(known_str)\r\n",
        "      unknown_str = \",\".join(unknown_exts)\r\n",
        "      msg += \"  skipping files with exts in [{0}]\".format(unknown_str)\r\n",
        "      print(msg)\r\n",
        "  files = [f for f in all_files if f.split(\".\")[-1] in known_exts]\r\n",
        "  if verbosity > 0:\r\n",
        "    n = 6\r\n",
        "    suff = \"...\" if len(files) > n else \"\"    \r\n",
        "    print(\"\\nloading files: [{0}{1}]\".format(\",\".join(files[:n]), suff))\r\n",
        "    print(\" from: {0}\".format(dpath))\r\n",
        "\r\n",
        "  for i, file in enumerate(tqdm(files, mininterval=0.01, smoothing=0.1)):\r\n",
        "    if verbosity > 0:\r\n",
        "      print(\"{0} '{1}'\".format(i, file))\r\n",
        "    parts = file.split(\".\")\r\n",
        "    if len(parts) != 2:\r\n",
        "      print(\"Cannot do {0}, exptecing format 'name.ext'\".format(file))\r\n",
        "      continue\r\n",
        "    obj_name, ext = parts\r\n",
        "    if verbosity > 0:\r\n",
        "      print(\"obj_name: '{0}', ext= '.{1}'\".format(obj_name, ext))\r\n",
        "    fpath = os.path.join(dpath, file)\r\n",
        "    if not os.path.isfile(fpath):\r\n",
        "      warnings.warn(\"{0} is not a filepath\".format(fpath))\r\n",
        "      continue\r\n",
        "    if verbosity > 0:\r\n",
        "      print(\"\\t{0} from {1}\".format(obj_name,file))    \r\n",
        "    if not force_reload:\r\n",
        "      if obj_name in globals().keys() :\r\n",
        "        print(\"{0} already in globals, not reloading\".format(obj_name))\r\n",
        "        continue\r\n",
        "      else:\r\n",
        "        print(\"{0} not in globals, must load\".format(obj_name))        \r\n",
        "\r\n",
        "    res[obj_name] = None\r\n",
        "    try:\r\n",
        "      if ext == \"parquet\":\r\n",
        "        with open(fpath, mode='rb') as file:\r\n",
        "          obj = pickle.load(file)\r\n",
        "          res[obj_name] = obj\r\n",
        "      elif ext == 'csv':\r\n",
        "        obj = pd.read_csv(fpath) \r\n",
        "    except Exception as e:\r\n",
        "      warnings.warn(\"  *Read Failed* on {0} \".format(file, dpath))\r\n",
        "      warnings.warn(str(e))\r\n",
        "    else:\r\n",
        "      res[obj_name] = obj\r\n",
        "      print(\"  OK {0} is type {1}\".format(obj_name, \r\n",
        "                                          type(res[obj_name])))\r\n",
        "  return res\r\n",
        "res = load_path_objects(dpath=dpath, force_reload=False, verbosity=2)\r\n",
        "for k in res.keys():\r\n",
        "  obj = res[k]\r\n",
        "  print(\"adding {0} type{1} to global namespace\".format(k, type(obj)))\r\n",
        "  globals()[k] = res[k]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 691.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "load_path_objects force_reload= False, extensions=('parquet', 'csv')\n",
            "\n",
            "loading files: [pairs_df_part1.csv,input_lang_part1.parquet,output_lang_part1.parquet,pairs_part1.parquet]\n",
            " from: /content/gdrive/My Drive/mlp_covid19/data/part1_output\n",
            "0 'pairs_df_part1.csv'\n",
            "obj_name: 'pairs_df_part1', ext= '.csv'\n",
            "\tpairs_df_part1 from pairs_df_part1.csv\n",
            "pairs_df_part1 already in globals, not reloading\n",
            "1 'input_lang_part1.parquet'\n",
            "obj_name: 'input_lang_part1', ext= '.parquet'\n",
            "\tinput_lang_part1 from input_lang_part1.parquet\n",
            "input_lang_part1 already in globals, not reloading\n",
            "2 'output_lang_part1.parquet'\n",
            "obj_name: 'output_lang_part1', ext= '.parquet'\n",
            "\toutput_lang_part1 from output_lang_part1.parquet\n",
            "output_lang_part1 already in globals, not reloading\n",
            "3 'pairs_part1.parquet'\n",
            "obj_name: 'pairs_part1', ext= '.parquet'\n",
            "\tpairs_part1 from pairs_part1.parquet\n",
            "pairs_part1 already in globals, not reloading\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul205PARZhx6",
        "outputId": "9a27a64c-5efd-49a0-ff53-dbdfa956039d"
      },
      "source": [
        "len(pairs_part1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "3MbtOLoPBm9_",
        "outputId": "3dc40f68-ed06-42e7-bbbc-88dbf15734c8"
      },
      "source": [
        "lendf = pd.DataFrame(pairs_df_part1['X'].apply(lambda x: len(x)))\r\n",
        "#lendf.plot.hist(bins=1000)\r\n",
        "cols = [len(x) < 4 for x in pairs_df_part1['X'].values]\r\n",
        "pairs_df_part1.loc[cols]\r\n",
        "#lendf.head()\r\n",
        "#pairs_df.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20508</th>\n",
              "      <td>L&gt;</td>\n",
              "      <td>Coronavirus, ecco i sintomi: sono gli stessi d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28568</th>\n",
              "      <td>E&gt;</td>\n",
              "      <td>Coronavirus cinese, Oms corregge valutazione: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58388</th>\n",
              "      <td>E&gt;</td>\n",
              "      <td>Coronavirus, donna di 54 anni sulla nave da cr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         X                                                  Y\n",
              "20508  L>   Coronavirus, ecco i sintomi: sono gli stessi d...\n",
              "28568  E>   Coronavirus cinese, Oms corregge valutazione: ...\n",
              "58388  E>   Coronavirus, donna di 54 anni sulla nave da cr..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyySf9hswk6I"
      },
      "source": [
        "'''\r\n",
        "Reusable set of functions to convert a tuple of strings (pair) to tensors\r\n",
        "Reference: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\r\n",
        "'''\r\n",
        "if True:\r\n",
        "  import torch\r\n",
        "\r\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "  def indexesFromSentence(lang, sentence):\r\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\r\n",
        "\r\n",
        "\r\n",
        "  def tensorFromSentence(lang, sentence):\r\n",
        "    indexes = indexesFromSentence(lang, sentence)\r\n",
        "    indexes.append(EOS_token)\r\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n",
        "\r\n",
        "\r\n",
        "  def tensorsFromPair(pair, input_lang, output_lang):\r\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\r\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\r\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b7Aav5QQkQG"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "  def __init__(self, input_size, hidden_size):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\r\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
        "\r\n",
        "  def initHidden(self):\r\n",
        "    self.hidden = torch.zeros(1, 1, self.hidden_size, device=device)\r\n",
        "\r\n",
        "  def forward(self, input, hidden):\r\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\r\n",
        "    output = embedded\r\n",
        "    output, hidden = self.gru(output, hidden)\r\n",
        "    return output, hidden"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWraVh7_sMgC"
      },
      "source": [
        "class EncoderRNN(nn.Module):\r\n",
        "  def __init__(self, input_size, hidden_size, verbosity=0):\r\n",
        "    super(EncoderRNN, self).__init__()\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.verbosity = verbosity\r\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\r\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
        "\r\n",
        "  def forward(self, input, hidden):\r\n",
        "    if self.verbosity > 0:\r\n",
        "      print(\"{0} input.shape {1}  hidden.shape {2}\".format(whoami(),\r\n",
        "                                                           input.shape, hidden.shape))\r\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\r\n",
        "    output = embedded\r\n",
        "    output, hidden = self.gru(output, hidden)\r\n",
        "    return output, hidden\r\n",
        "\r\n",
        "  def initHidden(self):\r\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it3SJ2DvmhOB"
      },
      "source": [
        "class DecoderRNN(nn.Module):\r\n",
        "  def __init__(self, hidden_size, output_size):\r\n",
        "    super(DecoderRNN, self).__init__()\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\r\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
        "    self.out = nn.Linear(hidden_size, output_size)\r\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\r\n",
        "\r\n",
        "  def forward(self, input, hidden):\r\n",
        "    output = self.embedding(input).view(1, 1, -1)\r\n",
        "    output = F.relu(output)\r\n",
        "    output, hidden = self.gru(output, hidden)\r\n",
        "    output = self.softmax(self.out(output[0]))\r\n",
        "    return output, hidden\r\n",
        "\r\n",
        "  def initHidden(self):\r\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGBLiR4Drvqp"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\r\n",
        "  def __init__(self, hidden_size, output_size, max_length, dropout_p=0.1,\r\n",
        "               verbosity=0):\r\n",
        "    super(AttnDecoderRNN, self).__init__()\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.output_size = output_size\r\n",
        "    self.dropout_p = dropout_p\r\n",
        "    self.max_length = max_length\r\n",
        "    self.verbosity = verbosity\r\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n",
        "    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\r\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\r\n",
        "\r\n",
        "  def forward(self, input, hidden, encoder_outputs):\r\n",
        "    if self.verbosity > 0:\r\n",
        "      print(\"{0} \".format(whoami()))  \r\n",
        "      print(\"input type {0}\".format(type(input)))  \r\n",
        "      print(\"hidden type {0}\".format(type(hidden)))        \r\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\r\n",
        "    embedded = self.dropout(embedded)\r\n",
        "\r\n",
        "    attn_weights = F.softmax(\r\n",
        "        self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n",
        "    if self.verbosity > 0:\r\n",
        "      print(\"  attn_weights.shape: {0}\".format(attn_weights.shape))\r\n",
        "      print(\"  encoder_outputs.shape: {0}\".format(encoder_outputs.shape))      \r\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n",
        "                              encoder_outputs.unsqueeze(0))\r\n",
        "\r\n",
        "    output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n",
        "    output = self.attn_combine(output).unsqueeze(0)\r\n",
        "\r\n",
        "    output = F.relu(output)\r\n",
        "    output, hidden = self.gru(output, hidden)\r\n",
        "\r\n",
        "    output = F.log_softmax(self.out(output[0]), dim=1)\r\n",
        "    return output, hidden, attn_weights\r\n",
        "\r\n",
        "  def initHidden(self):\r\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iacrcUt8v5jW"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, \r\n",
        "               max_length, \r\n",
        "               input_lang, output_lang, pairs,\r\n",
        "               print_every=1000, plot_every=100, \r\n",
        "               learning_rate=0.01, verbosity = 0):\r\n",
        "  if verbosity > 0:\r\n",
        "    print(\"{0} n_iters: {1}\".format(whoami(), n_iters))\r\n",
        "  start_dt = datetime.datetime.now()\r\n",
        "  plot_losses = []\r\n",
        "  print_loss_total = 0  # Reset every print_every\r\n",
        "  plot_loss_total = 0  # Reset every plot_every  \r\n",
        "\r\n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n",
        "  training_pairs = [tensorsFromPair(pair=random.choice(pairs), \r\n",
        "                                    input_lang=input_lang,\r\n",
        "                                    output_lang=output_lang) for i in range(n_iters)]\r\n",
        "  criterion = nn.NLLLoss()\r\n",
        "\r\n",
        "  if verbosity > 0:\r\n",
        "    print(\"Start iter dt:{0}\".format(start_dt))\r\n",
        "  losses = []\r\n",
        "  for iter in tqdm(range(0, n_iters), mininterval=0.1, smoothing=0.25):\r\n",
        "    if verbosity > 0:\r\n",
        "      if iter % print_every == 0:\r\n",
        "        print(iter+1,\"/\",n_iters)\r\n",
        "    training_pair = training_pairs[iter]\r\n",
        "    input_tensor = training_pair[0]\r\n",
        "    target_tensor = training_pair[1]\r\n",
        "\r\n",
        "    loss = train(input_tensor=input_tensor, target_tensor=target_tensor, \r\n",
        "                 max_length=max_length,\r\n",
        "                 encoder=encoder, decoder=decoder, \r\n",
        "                 encoder_optimizer=encoder_optimizer, \r\n",
        "                 decoder_optimizer=decoder_optimizer, \r\n",
        "                 criterion=criterion,\r\n",
        "                 verbosity=verbosity) \r\n",
        "    if verbosity > 0:  \r\n",
        "      if iter % print_every == 0:\r\n",
        "        print_loss_avg = print_loss_total / print_every\r\n",
        "        print_loss_total = 0\r\n",
        "        print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n",
        "                                      iter, iter / n_iters * 100, \r\n",
        "                                     print_loss_avg))\r\n",
        "\r\n",
        "    if iter % plot_every == 0:\r\n",
        "      plot_loss_avg = plot_loss_total / plot_every\r\n",
        "      plot_losses.append(plot_loss_avg)\r\n",
        "      plot_loss_total = 0\r\n",
        "  \r\n",
        "  showPlot(plot_losses)      \r\n",
        "\r\n",
        "def  train(input_tensor, target_tensor, encoder, decoder, \r\n",
        "           encoder_optimizer, decoder_optimizer, \r\n",
        "           criterion, max_length, \r\n",
        "           verbosity=0):\r\n",
        "  if verbosity > 0:\r\n",
        "    print(\"{0}\".format(whoami() ))\r\n",
        "    print(\"  input_tensor.shape {0}\".format(input_tensor.shape))\r\n",
        "    print(\"  target_tensor.shape: {0}\".format(target_tensor.shape))\r\n",
        "  encoder_hidden = encoder.initHidden()\r\n",
        "\r\n",
        "  encoder_optimizer.zero_grad()\r\n",
        "  decoder_optimizer.zero_grad()\r\n",
        "\r\n",
        "  input_length = input_tensor.size(0)\r\n",
        "  target_length = target_tensor.size(0)\r\n",
        "\r\n",
        "  encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\r\n",
        "  loss = 0\r\n",
        "  for i in tqdm(range(input_length)):\r\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor[i], \r\n",
        "                                             encoder_hidden)\r\n",
        "    encoder_outputs[i] = encoder_output[0, 0]\r\n",
        "  \r\n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\r\n",
        "  \r\n",
        "  decoder_hidden = encoder_hidden\r\n",
        "\r\n",
        "  teacher_forcing_ratio = 0.5\r\n",
        "  coin = np.round(random.random(), 3)\r\n",
        "  use_teacher_forcing = True if coin < teacher_forcing_ratio else False\r\n",
        "  if verbosity > 0:\r\n",
        "    msg = \"use_teacher_forcing: {0}\".format(use_teacher_forcing)\r\n",
        "    msg += \"\\n\\tcoin: {0} teacher_forcing_ratio: {1}\".format(coin, \r\n",
        "                                                         teacher_forcing_ratio)\r\n",
        "    print(msg)\r\n",
        "\r\n",
        "  if use_teacher_forcing:\r\n",
        "    # Teacher forcing: Feed the target as the next input\r\n",
        "    for di in range(target_length):\r\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\r\n",
        "           decoder_input, decoder_hidden, encoder_outputs)\r\n",
        "      loss += criterion(decoder_output, target_tensor[di])\r\n",
        "      decoder_input = target_tensor[di]  # Teacher forcing\r\n",
        "\r\n",
        "  else:\r\n",
        "    # Without teacher forcing: use its own predictions as the next input\r\n",
        "    for di in range(target_length):\r\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\r\n",
        "          decoder_input, decoder_hidden, encoder_outputs)\r\n",
        "      topv, topi = decoder_output.topk(1)\r\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\r\n",
        "\r\n",
        "      loss += criterion(decoder_output, target_tensor[di])\r\n",
        "      if decoder_input.item() == EOS_token:\r\n",
        "        break\r\n",
        "\r\n",
        "  loss.backward()\r\n",
        "\r\n",
        "  encoder_optimizer.step()\r\n",
        "  decoder_optimizer.step()  \r\n",
        "\r\n",
        "  return loss.item / target_length\r\n",
        "\r\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpfHROHFDO5r"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length,\r\n",
        "             verbosity=0):\r\n",
        "  with torch.no_grad():\r\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\r\n",
        "    input_length = input_tensor.size()[0]\r\n",
        "    encoder_hidden = encoder.initHidden()\r\n",
        "\r\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n",
        "    if verbosity > 0:\r\n",
        "      print(\"encoder outputs.shape {0}\".format(encoder_outputs.shape))\r\n",
        "      print(\"input_length= {0} initialing encoder input\".format(input_length))\r\n",
        "    for ei in range(input_length):\r\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n",
        "                                                  encoder_hidden)\r\n",
        "        if verbosity > 0:\r\n",
        "          print(\"{0} type \".format(type(encoder_output)))\r\n",
        "        encoder_outputs[ei] += encoder_output[0, 0]\r\n",
        "\r\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n",
        "\r\n",
        "    decoder_hidden = encoder_hidden\r\n",
        "\r\n",
        "    decoded_words = []\r\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\r\n",
        "\r\n",
        "    for di in range(max_length):\r\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\r\n",
        "          decoder_input, decoder_hidden, encoder_outputs)\r\n",
        "      decoder_attentions[di] = decoder_attention.data\r\n",
        "      topv, topi = decoder_output.data.topk(1)\r\n",
        "      if topi.item() == EOS_token:\r\n",
        "        decoded_words.append('<EOS>')\r\n",
        "        break\r\n",
        "      else:\r\n",
        "        decoded_words.append(output_lang.index2word[topi.item()])\r\n",
        "\r\n",
        "        decoder_input = topi.squeeze().detach()\r\n",
        "\r\n",
        "    return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpQnT9WcDhIt"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\r\n",
        "  for i in range(n):\r\n",
        "    pair = random.choice(pairs)\r\n",
        "    print('>', pair[0])\r\n",
        "    print('=', pair[1])\r\n",
        "    output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n",
        "    output_sentence = ' '.join(output_words)\r\n",
        "    print('<', output_sentence)\r\n",
        "    print('')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7pyaovGmCcz"
      },
      "source": [
        "######################################################################\r\n",
        "# We'll need a unique index per word to use as the inputs and targets of\r\n",
        "# the networks later. To keep track of all this we will use a helper class\r\n",
        "# called ``Lang`` which has word → index (``word2index``) and index → word\r\n",
        "# (``index2word``) dictionaries, as well as a count of each word\r\n",
        "# ``word2count`` to use to later replace rare words.\r\n",
        "#\r\n",
        "\r\n",
        "SOS_token = 0\r\n",
        "EOS_token = 1\r\n",
        "\r\n",
        "\r\n",
        "class Lang:\r\n",
        "    def __init__(self, name):\r\n",
        "        self.name = name\r\n",
        "        self.word2index = {}\r\n",
        "        self.word2count = {}\r\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n",
        "        self.n_words = 2  # Count SOS and EOS\r\n",
        "\r\n",
        "    def addSentence(self, sentence):\r\n",
        "        for word in sentence.split(' '):\r\n",
        "            self.addWord(word)\r\n",
        "\r\n",
        "    def addWord(self, word):\r\n",
        "        if word not in self.word2index:\r\n",
        "            self.word2index[word] = self.n_words\r\n",
        "            self.word2count[word] = 1\r\n",
        "            self.index2word[self.n_words] = word\r\n",
        "            self.n_words += 1\r\n",
        "        else:\r\n",
        "            self.word2count[word] += 1\r\n",
        "\r\n",
        "\r\n",
        "######################################################################\r\n",
        "# The files are all in Unicode, to simplify we will turn Unicode\r\n",
        "# characters to ASCII, make everything lowercase, and trim most\r\n",
        "# punctuation.\r\n",
        "#\r\n",
        "\r\n",
        "# Turn a Unicode string to plain ASCII, thanks to\r\n",
        "# https://stackoverflow.com/a/518232/2809427\r\n",
        "def unicodeToAscii(s):\r\n",
        "    return ''.join(\r\n",
        "        c for c in unicodedata.normalize('NFD', s)\r\n",
        "        if unicodedata.category(c) != 'Mn'\r\n",
        "    )\r\n",
        "\r\n",
        "# Lowercase, trim, and remove non-letter characters\r\n",
        "\r\n",
        "\r\n",
        "def normalizeString(s):\r\n",
        "    s = unicodeToAscii(s.lower().strip())\r\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n",
        "    return s\r\n",
        "\r\n",
        "\r\n",
        "######################################################################\r\n",
        "# To read the data file we will split the file into lines, and then split\r\n",
        "# lines into pairs. The files are all English → Other Language, so if we\r\n",
        "# want to translate from Other Language → English I added the ``reverse``\r\n",
        "# flag to reverse the pairs.\r\n",
        "#\r\n",
        "\r\n",
        "def readLangs(lang1, lang2, reverse=False):\r\n",
        "    print(\"Reading langs...\")\r\n",
        "\r\n",
        "    # Read the file and split into lines\r\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\r\n",
        "        read().strip().split('\\n')\r\n",
        "\r\n",
        "    # Split every line into pairs and normalize\r\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\r\n",
        "\r\n",
        "    # Reverse pairs, make Lang instances\r\n",
        "    if reverse:\r\n",
        "        pairs = [list(reversed(p)) for p in pairs]\r\n",
        "        input_lang = Lang(lang2)\r\n",
        "        output_lang = Lang(lang1)\r\n",
        "    else:\r\n",
        "        input_lang = Lang(lang1)\r\n",
        "        output_lang = Lang(lang2)\r\n",
        "\r\n",
        "    return input_lang, output_lang, pairs\r\n",
        "\r\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPs0ZQdIl2-8",
        "outputId": "50d4e1d8-bfb2-4d06-cfa3-fd0731a2922f"
      },
      "source": [
        "######################################################################\r\n",
        "# Since there are a *lot* of example sentences and we want to train\r\n",
        "# something quickly, we'll trim the data set to only relatively short and\r\n",
        "# simple sentences. Here the maximum length is 10 words (that includes\r\n",
        "# ending punctuation) and we're filtering to sentences that translate to\r\n",
        "# the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\r\n",
        "# earlier).\r\n",
        "#\r\n",
        "\r\n",
        "eng_prefixes = (\r\n",
        "    \"i am \", \"i m \",\r\n",
        "    \"he is\", \"he s \",\r\n",
        "    \"she is\", \"she s \",\r\n",
        "    \"you are\", \"you re \",\r\n",
        "    \"we are\", \"we re \",\r\n",
        "    \"they are\", \"they re \"\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def filterPair(p, max_length):\r\n",
        "    return len(p[0].split(' ')) < max_length and \\\r\n",
        "        len(p[1].split(' ')) < max_length and \\\r\n",
        "        p[1].startswith(eng_prefixes)\r\n",
        "\r\n",
        "\r\n",
        "def filterPairs(pairs, max_length, verbosity=0):\r\n",
        "  if verbosity > 0:\r\n",
        "    print(\"max_length={0}\".format(max_length))\r\n",
        "  return [pair for pair in pairs if filterPair(pair, max_length=max_length)]\r\n",
        "\r\n",
        "\r\n",
        "######################################################################\r\n",
        "# The full process for preparing the data is:\r\n",
        "#\r\n",
        "# -  Read text file and split into lines, split lines into pairs\r\n",
        "# -  Normalize text, filter by length and content\r\n",
        "# -  Make word lists from sentences in pairs\r\n",
        "#\r\n",
        "def prepareData(lang1, lang2, reverse=False):\r\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\r\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\r\n",
        "    pairs = filterPairs(pairs)\r\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\r\n",
        "    print(\"Counting words...\")\r\n",
        "    for pair in pairs:\r\n",
        "        input_lang.addSentence(pair[0])\r\n",
        "        output_lang.addSentence(pair[1])\r\n",
        "    print(\"Counted words:\")\r\n",
        "    print(input_lang.name, input_lang.n_words)\r\n",
        "    print(output_lang.name, output_lang.n_words)\r\n",
        "    return input_lang, output_lang, pairs\r\n",
        "\r\n",
        "def prepareData_jhm(input_lang, output_lang, pairs,\r\n",
        "                    max_length, verbosity=0):\r\n",
        "    #input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\r\n",
        "    #print(\"Read %s sentence pairs\" % len(pairs))\r\n",
        "    if verbosity > 0:\r\n",
        "      print(\"input pairs: {0}\".format(len(pairs)))    \r\n",
        "    #pairs = filterPairs(pairs, max_length=max_length, verbosity=verbosity)\r\n",
        "    if verbosity > 0:\r\n",
        "      print(\"Trimmed to {0} pairs\".format(len(pairs)))\r\n",
        "      print(\"Adding to lang\")\r\n",
        "    for pair in tqdm(pairs):\r\n",
        "        input_lang.addSentence(pair[0])\r\n",
        "        output_lang.addSentence(pair[1])\r\n",
        "        #if i > 10000:\r\n",
        "        #  break\r\n",
        "    print(\"Counted words:\")\r\n",
        "    #print(input_lang.name, input_lang.n_words)\r\n",
        "    #print(output_lang.name, output_lang.n_words)\r\n",
        "    return input_lang, output_lang, pairs\r\n",
        "\r\n",
        "#input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\r\n",
        "print(len(pairs_part1))\r\n",
        "if False:\r\n",
        "  parts = prepareData_jhm(\r\n",
        "        max_length =0,\r\n",
        "        input_lang=input_lang_part1,\r\n",
        "        output_lang=output_lang_part1,\r\n",
        "        pairs=pairs_part1,\r\n",
        "        verbosity=2)\r\n",
        "  if len(parts) != 3:\r\n",
        "    warnings.warn(\"Problem preparing the data\")\r\n",
        "  else:\r\n",
        "    input_lang, output_lang, pairs = parts\r\n",
        "  print(len(pairs))\r\n",
        "  #random.choices(pairs, k=10)  "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "amkt6QeabPdd",
        "outputId": "136e67b0-6f10-4f64-da61-8a9af948aa1f"
      },
      "source": [
        "verbosity = 2\r\n",
        "max_length = 600\r\n",
        "hidden_size = 300\r\n",
        "\r\n",
        "encoder = EncoderRNN(input_lang_part1.n_words, hidden_size, verbosity=2).to(device)\r\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang_part1.n_words, \r\n",
        "                         max_length=max_length, \r\n",
        "                         dropout_p=0.1, verbosity=2).to(device)\r\n",
        "if verbosity > 0:\r\n",
        "  print(\"encoder type= {0}\".format(type(encoder)))\r\n",
        "  print(\"decoder type= {0}\".format(type(decoder)))\r\n",
        "trainIters(encoder=encoder, decoder=decoder, n_iters=1000,\r\n",
        "           input_lang=input_lang_part1,\r\n",
        "           output_lang=output_lang_part1, \r\n",
        "           pairs=pairs_part1,\r\n",
        "           max_length=max_length,\r\n",
        "            print_every=1, plot_every=100,verbosity=2)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
            "  0%|          | 0/350 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "encoder type= <class '__main__.EncoderRNN'>\n",
            "decoder type= <class '__main__.AttnDecoderRNN'>\n",
            "trainIters n_iters: 1000\n",
            "Start iter dt:2020-12-14 05:43:11.618500\n",
            "1 / 1000\n",
            "train\n",
            "  input_tensor.shape torch.Size([350, 1])\n",
            "  target_tensor.shape: torch.Size([13, 1])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 2/350 [00:00<00:17, 19.90it/s]\u001b[A\n",
            " 34%|███▍      | 119/350 [00:00<00:08, 28.23it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 65%|██████▌   | 228/350 [00:00<00:03, 39.87it/s]\u001b[A\n",
            "100%|██████████| 350/350 [00:00<00:00, 826.90it/s]\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "forward input.shape torch.Size([1])  hidden.shape torch.Size([1, 1, 300])\n",
            "use_teacher_forcing: True\n",
            "\tcoin: 0.236 teacher_forcing_ratio: 0.5\n",
            "forward \n",
            "input type <class 'torch.Tensor'>\n",
            "hidden type <class 'torch.Tensor'>\n",
            "  attn_weights.shape: torch.Size([1, 600])\n",
            "  encoder_outputs.shape: torch.Size([350, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-613e66ffbfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m            \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs_part1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m            \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             print_every=1, plot_every=100,verbosity=2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-309c0e9b9569>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, max_length, input_lang, output_lang, pairs, print_every, plot_every, learning_rate, verbosity)\u001b[0m\n\u001b[1;32m     35\u001b[0m                  \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                  \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                  verbosity=verbosity) \n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbosity\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-309c0e9b9569>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, verbosity)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 93\u001b[0;31m            decoder_input, decoder_hidden, encoder_outputs)\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m       \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-e14ef4a84584>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  encoder_outputs.shape: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n\u001b[0;32m---> 31\u001b[0;31m                               encoder_outputs.unsqueeze(0))\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_applied\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 600 at dimension 1, but got size 350 for argument #2 'batch2' (while checking arguments for bmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgagpz1cwl6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ToGlcIBXda"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCrPGq4VBi7p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}