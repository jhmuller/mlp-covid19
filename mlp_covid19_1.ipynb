{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_covid19-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFRwQdi3IFq4YSbwDO5V4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhmuller/mlp-covid19/blob/main/mlp_covid19_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNIUVntFYDWe"
      },
      "source": [
        "# need to intall this every time on colab, not sure why but I do it\n",
        "try:\n",
        "  import fsspec\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  !pip install fsspec"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpi84TZlHZM4"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import unicodedata\n",
        "import warnings\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "import glob\n",
        "import fsspec\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "now = datetime.datetime.now\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def warning_on_one_line(message, category, filename, lineno, file=None, line=None):\n",
        "    return '\\033[1m' +\\\n",
        "    'line:%s  cat:<%s>  msg:%s'% (lineno, category.__name__, message) +\\\n",
        "     '\\033[0m' \n",
        "\n",
        "warnings.formatwarning = warning_on_one_line"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb55kMKvi_r_",
        "outputId": "778a6030-de47-4536-9824-0701ce3d8c67"
      },
      "source": [
        "warnings.warn(\"foo\")\n",
        "# hmm, colors not working, find a fix"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mline:1  cat:<UserWarning>  msg:foo\u001b[0m"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CfosqNUxpsT",
        "outputId": "a9c0a374-e3b3-4d6d-953d-29c23c2e36b8"
      },
      "source": [
        "# code to show what versions of modules I'm using\n",
        "import inspect\n",
        "mlist = list(filter(lambda x: inspect.ismodule(x[1]), locals().items()))\n",
        "vi = sys.version_info\n",
        "print(\"version {0}.{1}.{2} of Python\".format(vi.major, vi.minor, vi.micro))\n",
        "for name, mod in mlist:\n",
        "    mname = name\n",
        "    if name.startswith(\"__\"):\n",
        "      print(name, mod)\n",
        "      continue\n",
        "    if hasattr(mod, \"__version__\"):\n",
        "        mname = name\n",
        "        if hasattr(mod, \"__path__\"):\n",
        "            mname = os.path.split(mod.__path__[0])[1]\n",
        "        print(\"version {1} of {0} as {2} \".format(mname, name, mod.__version__))\n",
        "    elif hasattr(mod, \"__file__\") and \"site-packages\" in mod.__file__:\n",
        "        print(\"No __version__ for {0} as {1}\".format(mname, name))\n",
        "del mod\n",
        "del name"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "version 3.6.9 of Python\n",
            "__builtin__ <module 'builtins' (built-in)>\n",
            "__builtins__ <module 'builtins' (built-in)>\n",
            "version fsspec of fsspec as 0.8.4 \n",
            "version re of re as 2.2.1 \n",
            "version json of json as 2.0.9 \n",
            "version nltk of nltk as 3.2.5 \n",
            "version pd of pandas as 1.1.4 \n",
            "version np of numpy as 1.18.5 \n",
            "version torch of torch as 1.7.0+cu101 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDc60grsHt8v",
        "outputId": "8a7a93a4-445c-4147-ec45-e5d1cbde3a10"
      },
      "source": [
        "# to mount google drive for the input files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqcsZjItfGB3",
        "outputId": "9116b4fe-bbe5-4442-c354-5e64bf6e1a4d"
      },
      "source": [
        "# make a list of all the file paths in the data directory\n",
        "dpath = \"/content/gdrive/My Drive/data/mlp_covid19/16119_db21c91a1ab47385bb13773ed8238c31\"\n",
        "jfiles = os.listdir(dpath)\n",
        "jpaths = [os.path.join(dpath, jf) for jf in jfiles]\n",
        "print(jfiles[:4])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['16119_webhose_2020_03_db21c91a1ab47385bb13773ed8238c31_0000015.json', '16119_webhose_2020_03_db21c91a1ab47385bb13773ed8238c31_0000005.json', '16119_webhose_2020_03_db21c91a1ab47385bb13773ed8238c31_0000016.json', '16119_webhose_2020_03_db21c91a1ab47385bb13773ed8238c31_0000023.json']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzVXqfZ1fcJJ"
      },
      "source": [
        "# the files that we will use here\n",
        "files_set = set(\n",
        "    [\"16119_webhose_2019_12_db21c91a1ab47385bb13773ed8238c31_0000001.json\",\n",
        "      \"16119_webhose_2020_01_db21c91a1ab47385bb13773ed8238c31_0000001.json\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIy8kOgDfU_R",
        "outputId": "c78d2938-02c3-471c-bf76-03af12e917ae"
      },
      "source": [
        "# try reading the data in the first file using the json module\n",
        "# raised error\n",
        "f1 = list(files_set)[0]\n",
        "p1 = os.path.join(dpath, f1)\n",
        "try:\n",
        "  with open(p1) as f:\n",
        "    data = json.load(f)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  # sys.exc_info returns (type, value, traceback)\n",
        "  extype, exval, tb = sys.exc_info()\n",
        "  warnings.warn(str(extype))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extra data: line 2 column 1 (char 8133)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mline:12  cat:<UserWarning>  msg:<class 'json.decoder.JSONDecodeError'>\u001b[0m"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWvvDcg2ki25",
        "outputId": "385080a2-2a3a-4be3-c44e-3509dd208d47"
      },
      "source": [
        "# try reading the data with pandas\n",
        "# raised error\n",
        "f1 = list(files_set)[0]\n",
        "p1 = os.path.join(dpath, f1)\n",
        "try:\n",
        "  data = pd.read_json(p1)\n",
        "except Exception as e:\n",
        "  print(e)   \n",
        "  # sys.exc_info returns (type, value, traceback)\n",
        "  extype, exval, tb = sys.exc_info()\n",
        "  warnings.warn(str(extype)) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trailing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mline:11  cat:<UserWarning>  msg:<class 'ValueError'>\u001b[0m"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaivpL59h5PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f9a726-b657-4eac-c093-a03f39fde9bf"
      },
      "source": [
        "# So read in as text \n",
        "\n",
        "# only using 2 files\n",
        "# 16119_webhose_2019_12_db21c91a1ab47385bb13773ed8238c31_0000001.json \n",
        "# 16119_webhose_2020_01_db21c91a1ab47385bb13773ed8238c31_0000001.json.\n",
        "files_set = set(\n",
        "    [\"16119_webhose_2019_12_db21c91a1ab47385bb13773ed8238c31_0000001.json\",\n",
        "      \"16119_webhose_2020_01_db21c91a1ab47385bb13773ed8238c31_0000001.json\"])\n",
        "txt_data = ''\n",
        "for fpath in jpaths:\n",
        "  head, tail = os.path.split(fpath)\n",
        "  if tail in files_set:\n",
        "    print(\"reading {0} {1}\".format(tail, datetime.datetime.now()))\n",
        "    with open(jpaths[0], mode='r') as fp:\n",
        "      new_data = fp.read()\n",
        "    print(\"len {0} {1}\".format(len(new_data), datetime.datetime.now()))\n",
        "    txt_data += new_data\n",
        "\n",
        "print(\"len of txt data {0}\".format(len(txt_data)))\n",
        "print(now())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading 16119_webhose_2019_12_db21c91a1ab47385bb13773ed8238c31_0000001.json 2020-12-05 20:32:08.042493\n",
            "len 521195604 2020-12-05 20:32:11.483658\n",
            "reading 16119_webhose_2020_01_db21c91a1ab47385bb13773ed8238c31_0000001.json 2020-12-05 20:32:11.483906\n",
            "len 521195604 2020-12-05 20:32:15.009417\n",
            "len of txt data 1042391208\n",
            "2020-12-05 20:32:16.334985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFBKZUYmAqM5",
        "outputId": "f1ae08fb-bf82-490b-99b3-3e1fbff7de42"
      },
      "source": [
        "# split into lines\n",
        "# eval each line\n",
        "# WARNING: should not do this with untrusted files\n",
        "txt_lines = txt_data.split('\\n')\n",
        "print(\"{0} lines\".format(len(txt_lines)))\n",
        "dlist = []\n",
        "for i, l in enumerate(txt_lines):\n",
        "  try:\n",
        "    d = eval(l) \n",
        "    dlist.append(d)\n",
        "  except Exception as e:\n",
        "    print(\"line{0}, {1}\\n{2}\".format(i,l, e))\n",
        "print(\"len dlist {0}\".format(len(dlist)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197913 lines\n",
            "line98956, {\"organizations\": [], \"uuid\": \"50db3ae27600471c975e2b3f9ffae3693f861967\", \"thread\": {\"social\": {\"gplus\": {\"shares\": 0}, \"pinterest\": {\"shares\": 0}, \"vk\": {\"shares\": 0}, \"linkedin\": {\"shares\": 0}, \"facebook\": {\"likes\": 0, \"shares\": 0, \"comments\": 0}, \"stumbledupon\": {\"shares\": 0}}, \"site_full\": \"www.businessinsider.sg\", \"main_image\": \"https://static.businessinsider.sg/sites/2/2020/03/5c24ee842a5b7429c428e9cc.png\", \"site_section\": \"https://www.businessinsider.sg/career\", \"section_title\": \"Latest Career on Business Insider Singapore - Business Insider Singapore\", \"url\": \"https://www.businessinsider.sg/amazon-walmart-hiring-how-to-apply-2020-3\", \"country\": \"SG\", \"domain_rank\": 26759, \"title\": \"Amazon and Walmart are ramping up hiring to add 250,000 new jobs. Here's how to apply and whether you can expect an interview.,\", \"performance_score\": 0, \"site\": \"businessinsider.sg\", \"participants_count\": 1, \"title_full\": \"\", \"spam_score\": 0.027, \"site_type\": \"news\", \"published\": \"2020-03-23T11:55:00.000+02:00\", \"replies_count\": 0, \"uuid\": \"50db3ae27600471c975e2b3f9ffae3693f861967\"}, \"author\": \"Hayley Peterson\", \"url\": \"https://www.businessinsider.sg/amazon-walmart-hiring-how-to-apply-2020-3\", \"ord_in_thread\": 0, \"title\": \"Amazon and Walmart are ramping up hiring to add 250,000 new jobs. Here's how to apply and whether you can expect an interview.,\", \"locations\": [], \"entities\": {\"persons\": [], \"locations\": [{\"name\": \"us\", \"sentiment\": \"none\"}], \"organizations\": [{\"name\": \"amazon\", \"sentiment\": \"negative\"}, {\"name\": \"walmart\", \"sentiment\": \"negative\"}]}, \"highlightText\": \"\", \"language\": \"english\", \"persons\": [], \"text\": \"Amazon and Walmart are launching immediate hiring sprees to address surging consumer demand stemming from the coronavirus pandemic.\\nAmazon has said it plans to hire 100,000 US warehouse and delivery workers, while Walmart aims to add 150,000 new employees through the end of May to work in stores, clubs, distribution centers, and fulfillment centers. The Walmart roles will initially be temporary, but many will convert to permanent roles over time, the company said.\\nHere’s what you need to know about the new roles and hiring processes at each company.\\nAmazon is staffing up in three main categories: warehouses, shoppers, and delivery drivers.\\nHere’s a breakdown of the three categories where Amazon is focusing its hiring:\\nAmazon’s hiring process, from submitting an application to starting work, can take as little as seven days and involves no resumes or interviews.\\nAmazon’s available positions and online applications can be found on the company’s jobs site . Here are the key steps:\\nThe entire process, from application to the first day of work, can take as little as seven days, according to Amazon.\\n“No resume or previous work experience required,” the company says on its website.\\nDelivery driver roles do require interviews, however.\\nAs Walmart ramps up its staff, it plans to speed up hiring for key roles including cashiers and stockers by cutting the application process from an average of two weeks to 24 hours.\\nHere are some of the roles where Walmart is adding staff:\", \"external_links\": [\"https://i.insider.com/5ad705e2e52c2d28008b4707\", \"https://www.i.insider.com/5e78d9e02d654f1f74350fb3\", \"https://www.i.insider.com/5c24ee842a5b7429c428e9cc\", \"https://www.businessinsider.com/amazon-100000-new-hires-and-pay-raise-amid-coronavirus-2020-3\", \"https://amazondelivers.jobs/?cmpid=PRPRLC0780H6\", \"https://i.insider.com/5e78d9e02d654f1f74350fb3\", \"https://www.amazondelivers.jobs/?cmpid=PRPRLC0780H6\", \"https://i.insider.com/5c89111569e11c12066532ca\", \"https://i.insider.com/5c24ee842a5b7429c428e9cc\", \"https://www.businessinsider.com/walmart-to-pay-employee-bonuses-and-hire-150000-workers-2020-3\", \"https://www.i.insider.com/5c89111569e11c12066532ca\", \"https://www.i.insider.com/5ad705e2e52c2d28008b4707\", \"https://www.amazondelivers.jobs/\", \"https://businessinsider.com/amazon-100000-new-hires-and-pay-raise-amid-coronavirus-2020-3\", \"https://businessinsider.com/walmart-to-pay-employee-bonuses-and-hire-150000-workers-2020-3\"], \"published\": \"2020-03-23T11:55:00.000+02:00\", \"crawled\": \"2020-03-24T16:16:31.081+02:00\", \"highlightTitle\": \"\"}{\"organizations\": [], \"uuid\": \"e1f229c830df943457586af99d3569848a796aeb\", \"thread\": {\"social\": {\"gplus\": {\"shares\": 0}, \"pinterest\": {\"shares\": 0}, \"vk\": {\"shares\": 0}, \"linkedin\": {\"shares\": 0}, \"facebook\": {\"likes\": 0, \"shares\": 0, \"comments\": 0}, \"stumbledupon\": {\"shares\": 0}}, \"site_full\": \"www.newkerala.com\", \"main_image\": \"\", \"site_section\": \"http://www.newkerala.com/india-news.xml\", \"section_title\": \"India News Update\", \"url\": \"https://www.newkerala.com/news/2020/47081.htm\", \"country\": \"US\", \"domain_rank\": 61094, \"title\": \"COVID-19: Goa SEC cancels March 24 ZP polls; board exams postponed\", \"performance_score\": 0, \"site\": \"newkerala.com\", \"participants_count\": 0, \"title_full\": \"\", \"spam_score\": 0.0, \"site_type\": \"news\", \"published\": \"2020-03-21T03:01:00.000+02:00\", \"replies_count\": 0, \"uuid\": \"e1f229c830df943457586af99d3569848a796aeb\"}, \"author\": \"\", \"url\": \"https://www.newkerala.com/news/2020/47081.htm\", \"ord_in_thread\": 0, \"title\": \"COVID-19: Goa SEC cancels March 24 ZP polls; board exams postponed\", \"locations\": [], \"entities\": {\"persons\": [{\"name\": \"narendra modi\", \"sentiment\": \"none\"}, {\"name\": \"goa\", \"sentiment\": \"none\"}, {\"name\": \"r.k. srivastava\", \"sentiment\": \"none\"}, {\"name\": \"pramod sawant\", \"sentiment\": \"none\"}], \"locations\": [{\"name\": \"panaji\", \"sentiment\": \"none\"}, {\"name\": \"goa\", \"sentiment\": \"none\"}], \"organizations\": [{\"name\": \"goa sec\", \"sentiment\": \"negative\"}, {\"name\": \"sec\", \"sentiment\": \"none\"}, {\"name\": \"zila panchayat\", \"sentiment\": \"none\"}, {\"name\": \"bombay high court\", \"sentiment\": \"none\"}]}, \"highlightText\": \"\", \"language\": \"english\", \"persons\": [], \"text\": \"India News COVID-19: Goa SEC cancels March 24 ZP polls; board exams postponed Panaji, March 20 : In wake of the coronavirus scare, the March 24 elections to 50 Zila Panchayat seats were cancelled on Friday by the state election body. A fresh poll schedule will be announced later. On Friday, the state also postponed Board examinations of Class X and XII as well as for Class IX and XI. \\\"The elections have been cancelled. Fresh dates will be announced later,\\\" State Election Commissioner R.K. Srivastava told reporters here.Incidentally, Goa has not reported a single coronavirus positive case yet.The SEC decision came on a day when a Bombay High Court bench in Goa also directed the election panel to reconsider the holding of polls on March 24 in view of mass gatherings such an exercise necessitates.The polls were scheduled to be held on March 22, but later postponed to March 24 by Chief Minister Pramod Sawant on Thursday, after Prime Minister Narendra Modi designated March 22 as a day to observe 'janata curfew' in view of the coronavirus scare.The BJP-led coalition government in the coastal state has faced severe criticism from the opposition and civil society for refusing to postpone the Zila Panchayat polls. (IANS)\", \"external_links\": [], \"published\": \"2020-03-21T03:01:00.000+02:00\", \"crawled\": \"2020-03-21T06:35:34.008+02:00\", \"highlightTitle\": \"\"}\n",
            "invalid syntax (<string>, line 1)\n",
            "len dlist 197912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygdUHiJgDZ5S",
        "outputId": "e5a41492-8f6c-4330-9a4b-221a1938edf5"
      },
      "source": [
        "#extract text and title\n",
        "dataset = [d['text'] for d in dlist]\n",
        "target = [d['title'] for d in dlist]\n",
        "# The length of the list dataset and target will be 190138.\n",
        "print(\"dataset len= {0}, target len= {1}\\n\".format(len(dataset), len(target)))\n",
        "names = (\"dataset\", \"target\")\n",
        "n = 2\n",
        "for name in names:\n",
        "  print(\"first {0} from {1}\".format(n,name))\n",
        "  items = eval(name)[:n]\n",
        "  maxlen = 30\n",
        "  for i, item in enumerate(items):\n",
        "    suffix = \"...\" if len(item) > maxlen else \"\"\n",
        "    print(\"{0}: {1}{2}\".format(i, item[:maxlen], suffix))\n",
        "  print()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset len= 197912, target len= 197912\n",
            "\n",
            "first 2 from dataset\n",
            "0: India News COVID-19: Goa SEC c...\n",
            "1: John Legend: 'The Voice' episo...\n",
            "\n",
            "first 2 from target\n",
            "0: COVID-19: Goa SEC cancels Marc...\n",
            "1: EarthLink - News\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyuzGAmEiljm"
      },
      "source": [
        "contraction_map = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALIyEgLuiopU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5e1fcc-2a79-48c6-98e0-8347a1e8d50a"
      },
      "source": [
        "# took a litte trial and error to get that\n",
        "# have to call nltk.download() first\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))  \n",
        "print(type(stop_words))\n",
        "print(list(stop_words)[:4])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<class 'set'>\n",
            "['in', 'where', 'myself', 'own']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DU_hVJy95xU",
        "outputId": "502beb2d-5200-40b7-9831-631180ed229d"
      },
      "source": [
        "# my preprocess funtion\n",
        "def preprocess(text, contraction_map= None, stop_words = None):\n",
        "  if not contraction_map:\n",
        "    contraction_map = {}\n",
        "  if not stop_words:\n",
        "    stop_words = []\n",
        "  if not isinstance(stop_words, set):\n",
        "    stop_words = set(stop_words)\n",
        "\n",
        "  # Split the text using Python split() function\n",
        "  toks = text.split()\n",
        "  # Apply the contraction hashmap on all the words of the text\n",
        "  toks = [contraction_map[x] if x in contraction_map.keys() else x for x in toks]  \n",
        "  # Remove the stopwords that are in English\n",
        "  toks = [x for x in toks if x not in stop_words]\n",
        "\n",
        "  # now rejoin to apply other transforms on text string\n",
        "  res = ' '.join(toks)\n",
        "  # Convert text to lowercase\n",
        "  res = res.lower()    \n",
        "  # Remove 's. For example yours becomes your\n",
        "  res = res.replace(\"'s\",'') # convert your's -> your\n",
        "  # Use regular expression to remove parentheses outside a word. For example (word) becomes word\n",
        "  res = re.sub(\"\\(|\\)\", \"\", res) \n",
        "  # Use regular expression to remove punctuations\n",
        "  res = re.sub(r'[^a-zA-Z0-9. ]','',res)\n",
        "  # Use regular expression to add a space character before and after the full stop. For example . becomes .\n",
        "  res = re.sub(\"\\.\", \" . \", res)\n",
        "  return res\n",
        "test = \"The boys can't .(go) there!.\"\n",
        "test_out = preprocess(test, \n",
        "           contraction_map=contraction_map, \n",
        "           stop_words=stop_words)\n",
        "print(\"{0}\\n{1}\".format(test, test_out))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The boys can't .(go) there!.\n",
            "the boys cannot  . go there . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvwgRrUZ6NKN",
        "outputId": "7d49addb-f3bd-49e0-e21b-9cb782f94013"
      },
      "source": [
        "# suggested preprocess function\n",
        "def preprocess_ref(text, contraction_map, stop_words):\n",
        "    text = text.lower() # lowercase\n",
        "    text = text.split() # convert have'nt -> have not\n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        if word in contraction_map:\n",
        "            text[i] = contraction_map[word]\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'') # convert your's -> your\n",
        "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
        "    text = re.sub(r'\\.',' . ',text)\n",
        "    return text\n",
        "test = \"The boys can't .(go) there!.\"\n",
        "test_out = preprocess(test, \n",
        "           contraction_map=contraction_map, \n",
        "           stop_words=stop_words)\n",
        "print(\"{0}\\n{1}\".format(test, test_out))    "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The boys can't .(go) there!.\n",
            "the boys cannot  . go there . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS9ywQuj3WYU",
        "outputId": "5bf63b67-0d51-454e-900f-321927dbbbc1"
      },
      "source": [
        "%time X = [preprocess(line, contraction_map=contraction_map, stop_words=stop_words) for line in dataset]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 43.7 s, sys: 2.04 s, total: 45.8 s\n",
            "Wall time: 45.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DTek3AM6YzT",
        "outputId": "96abf311-bd23-4e2b-b3c2-aff678cd7c7c"
      },
      "source": [
        "%time X_ref = [preprocess_ref(line, contraction_map=contraction_map, stop_words=stop_words) for line in dataset]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.5 s, sys: 2.71 s, total: 51.2 s\n",
            "Wall time: 51.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U97VFu6Qm6yY",
        "outputId": "ef36bd4c-0916-40e3-b427-f2634f3e5dd4"
      },
      "source": [
        "%time Y = [preprocess(line, contraction_map=contraction_map, stop_words=stop_words) for line in target]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.68 s, sys: 30.8 ms, total: 1.71 s\n",
            "Wall time: 1.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sW2ra767bV5",
        "outputId": "97d9f862-4bec-4654-8dcf-35de933e6474"
      },
      "source": [
        "%time Y_ref = [preprocess_ref(line, contraction_map=contraction_map, stop_words=stop_words) for line in target]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.75 s, sys: 29.8 ms, total: 1.78 s\n",
            "Wall time: 1.78 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9exip0tP8PA1",
        "outputId": "39878640-84b9-48ab-9ea1-184fb5231939"
      },
      "source": [
        "# At this point, the length of X and Y should both be 190138.\n",
        "print(\"len X= {0}, len Y= {1}\".format(len(X), len(Y)))\n",
        "print(\"len X_ref= {0}, len Y_ref= {1}\".format(len(X_ref), len(Y_ref)))\n",
        "#assert(len(x) == 190138)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len X= 197912, len Y= 197912\n",
            "len X_ref= 197912, len Y_ref= 197912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyldRzFxE6go",
        "outputId": "2394f41c-24b6-40e3-8ee7-babd5098dc0a"
      },
      "source": [
        "# How does this relate to the delivarble?\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "max_len_text = 600\n",
        "max_len_target = 30\n",
        "for i in range(len(dataset)):\n",
        "    if(len(target[i].split())<=max_len_target and len(dataset[i].split())<=max_len_text):\n",
        "        short_text.append(dataset[i])\n",
        "        short_summary.append(target[i])\n",
        "\n",
        "temp_df=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
        "print(\"temp_df shape {0}\".format(temp_df.shape))\n",
        "# len(temp_df) being 130736."
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "temp_df shape (143468, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "m5wMOl6OE8m2",
        "outputId": "acc4a0d7-5d5b-45ff-f790-808031b56035"
      },
      "source": [
        "temp_df.head(2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>India News COVID-19: Goa SEC cancels March 24 ...</td>\n",
              "      <td>COVID-19: Goa SEC cancels March 24 ZP polls; b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John Legend: 'The Voice' episodes taped until ...</td>\n",
              "      <td>EarthLink - News</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  India News COVID-19: Goa SEC cancels March 24 ...  COVID-19: Goa SEC cancels March 24 ZP polls; b...\n",
              "1  John Legend: 'The Voice' episodes taped until ...                                   EarthLink - News"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3cdEBXyNeWl",
        "outputId": "8a3b45ff-3e18-497c-c4db-681379cb3ed2"
      },
      "source": [
        "# remove empty strings from summary and the text column.\n",
        "newdf = temp_df[temp_df['summary'].str.strip().astype(bool)]\n",
        "df = newdf[newdf['text'].str.strip().astype(bool)]\n",
        "print(\"df shape {0}\".format(df.shape))\n",
        "print(df.head(3))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df shape (130950, 2)\n",
            "                                                text                                            summary\n",
            "0  India News COVID-19: Goa SEC cancels March 24 ...  COVID-19: Goa SEC cancels March 24 ZP polls; b...\n",
            "1  John Legend: 'The Voice' episodes taped until ...                                   EarthLink - News\n",
            "2  Administrative Leave Offered to County Workers...     Administrative Leave Offered to County Workers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3HWOJpqNgVj"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "ViAGaYl7PKP5",
        "outputId": "7dc5b573-93de-46c4-fd8f-c48e2667aadf"
      },
      "source": [
        "df.head(2)\n",
        "X = list(df['text'].values)\n",
        "Y = list(df['summary'].values)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'txext'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-b682a3de6d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'txext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'txext'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxpzjoD1PbK3"
      },
      "source": [
        "def readData(text, summary):\n",
        "  print(\"Reading lines...\")\n",
        "  input_lang = Lang(text)\n",
        "  output_lang = Lang(summary)\n",
        "  pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "  return (input_lang, output_lang, pairs)\n",
        "\n",
        "def prepareData(tlist, slist):\n",
        "  input_lang, output_lang, pairs = readData(tlist, slist)\n",
        "  print(\"Read %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words...\")  \n",
        "  [input_lang.addSentence(t) for t in tlist]\n",
        "  [output_lang.addSentence(s) for s in slist] \n",
        "  return input_lang, output_lang, pairs "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY_nhTmMT5Oc",
        "outputId": "932f9d96-d227-4a65-c574-c1a6282061b5"
      },
      "source": [
        "input, output, pairs = prepareData(X,Y)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 197912 sentence pairs\n",
            "Counting words...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybE_WimPUeNg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}